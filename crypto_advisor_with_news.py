# -*- coding: utf-8 -*-
"""Crypto Advisor With News.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BnyUzCYTJE-sUyjEkZDM-CJRhpz7vgKh
"""

!pip install langchain langchain-community chromadb sentence-transformers
!pip install gradio

import os
import time
import json
import requests
import pandas as pd
from bs4 import BeautifulSoup
from sentence_transformers import SentenceTransformer
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import SentenceTransformerEmbeddings
from langchain.schema import Document
import pickle
import gradio as gr
from datetime import datetime
import plotly.graph_objects as go

from google.colab import drive
drive.mount('/content/drive')

# Step 1: Load Metadata or Cached Data
metadata_path = "/content/drive/MyDrive/files for ML/news.news_metadata.csv"
scraped_data_pkl = "/content/drive/MyDrive/files for ML/cached_scraped_articles.pkl"

if os.path.exists(scraped_data_pkl):
    with open(scraped_data_pkl, "rb") as f:
        df_news = pickle.load(f)
else:
    df_news = pd.read_csv(metadata_path)[["title", "source_article_description", "news_url", "publish_time"]]
    df_news["publish_time"] = pd.to_datetime(df_news["publish_time"])

    def scrape_cointelegraph_url(news_url):
        try:
            response = requests.get(news_url, timeout=10)
            if response.ok:
                soup = BeautifulSoup(response.content, "html.parser")
                article_tag = soup.find("article")
                return article_tag.get_text(strip=True) if article_tag else None
        except:
            return None

    df_news["full_text"] = df_news["news_url"].apply(scrape_cointelegraph_url)
    df_news.dropna(subset=["full_text"], inplace=True)
    df_news = df_news[df_news["full_text"].str.len() > 50]

    with open(scraped_data_pkl, "wb") as f:
        pickle.dump(df_news, f)

# Step 2: Chunking and Document Creation
text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)

documents = []
for i, row in df_news.iterrows():
    chunks = text_splitter.split_text(row["full_text"])
    for chunk in chunks:
        documents.append(Document(
            page_content=chunk,
            metadata={"title": row["title"], "url": row["news_url"], "publish_time": row["publish_time"].strftime("%Y-%m-%d")}
        ))

# Step 3: Create Vector DB (Chroma)
embedding_function = SentenceTransformerEmbeddings(model_name="all-MiniLM-L6-v2")
chroma_dir = "chroma_db"

if os.path.exists(chroma_dir):
    vectordb = Chroma(persist_directory=chroma_dir, embedding_function=embedding_function)
else:
    vectordb = Chroma.from_documents(documents, embedding_function, persist_directory=chroma_dir)
    vectordb.persist()

# Step 4: Querying from Together.AI
TOGETHER_AI_API_KEY = "tyour api key"

def query_mistral7b(prompt, max_tokens=300, temperature=0.7, top_p=0.9, retries=3, wait_time=5):
    url = "https://api.together.xyz/v1/completions"
    headers = {
        "Authorization": f"Bearer {TOGETHER_AI_API_KEY}",
        "Content-Type": "application/json"
    }
    payload = {
        "model": "mistralai/Mistral-7B-Instruct-v0.1",
        "prompt": prompt,
        "max_tokens": max_tokens,
        "temperature": temperature,
        "top_p": top_p
    }

    for attempt in range(retries):
        response = requests.post(url, headers=headers, json=payload)
        try:
            response_json = response.json()
            if response.status_code == 200 and "choices" in response_json:
                return response_json["choices"][0].get("text", "")
            elif response.status_code == 503:
                time.sleep(wait_time)
                wait_time *= 2
            else:
                print(f"API Error {response.status_code}: {response.text}")
                return None
        except Exception as e:
            print(f"Error: {e} - Response: {response.text}")
            return None
    return "LLM not responding."

from datetime import datetime

def generate_response(query, max_tokens=300, temperature=0.7, top_p=0.9, top_k=4):
    # Step 1: Over-fetch chunks
    all_docs = vectordb.similarity_search(query, k=top_k * 5)

    # Step 2: Deduplicate based on URL while keeping only the best chunk per article
    seen_urls = {}
    for doc in all_docs:
        url = doc.metadata.get("url")
        if not url:
            continue

        # Prefer the first or latest-scoring chunk
        if url not in seen_urls:
            seen_urls[url] = doc

    # Step 3: Score by recency
    def recency_boost(doc):
        try:
            pub_date = datetime.strptime(doc.metadata.get("publish_time", ""), "%Y-%m-%d")
            days_old = (datetime.now() - pub_date).days
            return 1 / (1 + days_old)
        except:
            return 0

    unique_docs = list(seen_urls.values())
    sorted_docs = sorted(unique_docs, key=recency_boost, reverse=True)[:top_k]

    # Step 4: Compose prompt
    context = "\n\n".join([doc.page_content for doc in sorted_docs])
    metadata_list = [doc.metadata for doc in sorted_docs]

    prompt = f"""
    Use the following recent news articles to answer the question clearly and factually:
    {context}

    Question:
    {query}
    """

    response = query_mistral7b(prompt, max_tokens=max_tokens, temperature=temperature, top_p=top_p)

    return {
        "response": response.strip(),
        "sources": metadata_list
    }

def fetch_price_and_chart(coin_id="bitcoin", days=7):
    url = f"https://api.coingecko.com/api/v3/coins/{coin_id}/market_chart?vs_currency=usd&days={days}"
    data = requests.get(url).json()

    if "prices" not in data:
        return "No price data found.", None

    prices = data["prices"]
    timestamps = [datetime.fromtimestamp(p[0] / 1000) for p in prices]
    values = [p[1] for p in prices]

    fig = go.Figure()
    fig.add_trace(go.Scatter(x=timestamps, y=values, mode='lines+markers', name=coin_id))
    fig.update_layout(title=f"{coin_id.capitalize()} Price Trend ({days} days)", xaxis_title='Date', yaxis_title='Price (USD)')
    return f"Latest Price: ${values[-1]:.2f}", fig

# -------------------- Step 6.1: Top Movers --------------------
def fetch_top_movers():
    url = "https://api.coingecko.com/api/v3/coins/markets?vs_currency=usd&order=market_cap_desc&per_page=50&page=1&price_change_percentage=24h"
    data = requests.get(url).json()

    sorted_data = sorted(data, key=lambda x: x['price_change_percentage_24h'] or 0, reverse=True)
    gainers = sorted_data[:3]
    losers = sorted_data[-3:]

    gainers_text = "\n".join([f"{coin['name']}: +{coin['price_change_percentage_24h']:.2f}%" for coin in gainers])
    losers_text = "\n".join([f"{coin['name']}: {coin['price_change_percentage_24h']:.2f}%" for coin in losers])

    return f"üîº Top Gainers (24h):\n{gainers_text}\n\nüîΩ Top Losers (24h):\n{losers_text}"

# -------------------- Step 7: Gradio Interface --------------------
def run_rag_interface(query, coin, duration, max_tokens, temperature, top_p):
    result = generate_response(query, max_tokens=max_tokens, temperature=temperature, top_p=top_p)
    sources = "<br><br>".join([
        f"<a href='{src['url']}' target='_blank'>{src['title']} ({src['publish_time']})</a>"
        for src in result["sources"]
    ])


    price_text, fig = fetch_price_and_chart(coin.lower(), int(duration))
    top_movers = fetch_top_movers()

    return result["response"], sources, price_text, fig, top_movers


iface = gr.Interface(
    fn=run_rag_interface,
    inputs=[
        gr.Textbox(label="Your Query", placeholder="Ask about crypto trends...", lines=2),
        gr.Textbox(label="Coin ID (e.g., bitcoin, ethereum)", placeholder="bitcoin"),
        gr.Radio(choices=["1", "7", "30", "90", "365"], label="Select Time Range (days)", value="7"),

        gr.Slider(
            minimum=100,
            maximum=600,
            value=300,
            step=50,
            label="Answer Length (Max Words)",
            info="Controls how long the model's response can be."
        ),

        gr.Slider(
            minimum=0.1,
            maximum=1.0,
            value=0.7,
            step=0.1,
            label="Answer Style (Factual ‚ÜîÔ∏è Creative)",
            info="Lower = more fact-based, Higher = more creative expression."
        ),

        gr.Slider(
            minimum=0.1,
            maximum=1.0,
            value=0.9,
            step=0.1,
            label="Answer Variety (Focused ‚ÜîÔ∏è Diverse)",
            info="Controls how varied the model's responses can be."
        )
    ],
    outputs=[
        gr.Textbox(label="Generated Answer"),
        gr.HTML(label="Sources"),
        gr.Textbox(label="Latest Price"),
        gr.Plot(label="Interactive Price Chart"),
        gr.Textbox(label="Top Gainers & Losers (24h)")
    ],
    title="üß† RAG Crypto Analyst with Interactive Chart"
)

iface.launch()
